{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f723d4f2-0ccf-4278-bfd1-60ce1ffa33b2",
   "metadata": {},
   "source": [
    "### **RISCO DE FOGO: QUEIMADAS NO CERRADO**\n",
    "<hr>\n",
    "<p align=\"justify\">\n",
    "Este trabalho é referente as tarefas desenvolvidas no Bloco 1. Espera-se desenvolver um projeto capaz de utilizar os comandos aprendidos pela linguagem de programação Python, na disciplina de Aprendizado de Máquina, além de desenvolver um sistema de previsão através de Machine Learning. O grupo desenvolvedor é composto pelas discentes:\n",
    "<p align=\"justify\">\n",
    "Isabela Bento Beneti </p>\n",
    "<p align=\"justify\">\n",
    "Monyque Karoline de Paula Silva </p>\n",
    "<p align=\"justify\">\n",
    "Sofia Baccega C.C. de Oliveira </p>\n",
    "<p align=\"justify\">\n",
    "Sophia Figueiredo Michel </p>\n",
    "<hr>\n",
    "\n",
    "### **Início:**\n",
    "<p align=\"justify\">\n",
    "Em um primento momento, iremos demonstrar o processo de tratamento dos dados obtidos via Database do INPE a respeito dos focos de incêndio ocorridos no Cerrado durante o período Janeiro-Julho(2022). É necessário realizar as padronizações de bibliotecas inicias, como a Pandas, Seaborn e Matplotlib, posteriormente, trabalha-se os dados até a otimização destes para a análise dos atríbutos escolhidos.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bf04d8-0846-458f-8daa-7478fce608ce",
   "metadata": {},
   "source": [
    "### **Coleta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d599a2b6-ef46-47d1-ba4c-39692c0926f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from itertools import product\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7b240f1e-4a9b-4f32-8d61-b33c8ddb6928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dados do Cerrado Brasileiro, armazenados mensalmente via .csv\n",
    "arquivos = ['janeiro.csv','fev.csv','marco.csv','abril.csv','maio.csv','junho.csv','julho.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "437be181-8d79-4dc6-a734-c0ad9b2272f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(list_of_files):\n",
    "    dfs = []\n",
    "    for x in list_of_files:\n",
    "        file = pd.read_csv(x, sep=',')\n",
    "        dfs.append(file)\n",
    "    df = pd.concat(dfs).reset_index(drop=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a7f83c41-9b26-4e21-bc62-817d9330febd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'janeiro.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SOFIA2~1\\AppData\\Local\\Temp/ipykernel_33004/4104563863.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmeses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marquivos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\SOFIA2~1\\AppData\\Local\\Temp/ipykernel_33004/2853560321.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(list_of_files)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_of_files\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mdfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\venv\\ilumpy\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\venv\\ilumpy\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\venv\\ilumpy\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\venv\\ilumpy\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\venv\\ilumpy\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\venv\\ilumpy\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\venv\\ilumpy\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\venv\\ilumpy\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'janeiro.csv'"
     ]
    }
   ],
   "source": [
    "meses = read_csv(arquivos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e088e9bd-6184-4523-80df-e26d0d77ebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dados trabalhados para a eliminação de NaN nas colunas e identificação dos tipos de dados\n",
    "meses.convert_dtypes()\n",
    "meses.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99c37ad-e536-4116-a17f-dfd1365c9c03",
   "metadata": {},
   "source": [
    "Eliminado as linhas dos dados não atribuidos(NaN), as desenvolvedoras optaram pelo uso do comando drop, do Pandas, de modo a selecionar as colunas não desejadas do arquvivo .csv, otimizando o processo de análise de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55ee367-b6c9-4cbe-8710-a147d3810ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Para rodar o código pela primeira vez, descomente essas linhas\n",
    "\n",
    "meses.drop(columns=['Unnamed: 0','estado', 'satelite', 'municipio', 'pais', 'municipio_id', 'estado_id', 'pais_id', 'bioma'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b6ebd4-0128-459c-8ca4-13fdd0d28332",
   "metadata": {},
   "outputs": [],
   "source": [
    "meses_fogo = meses['risco_fogo'] > 0\n",
    "meses = meses[meses_fogo]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d817b37-a484-4cf7-a5ff-4e8ec536b5a0",
   "metadata": {},
   "source": [
    "Realizada o processo de seleção de colunas, o próximo passo consiste na identificação dos tipos de dados utilizados em cada coluna e especificamente, em nosso caso, na identificação se dé fato só está sendo utilizado as variáveis numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adeea55-4c6b-471b-b384-bf1aff6fdda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "meses.dtypes, meses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b4957c-06b9-4265-8e93-90780b4c2ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(meses.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ff7fee-e4e7-4be4-b97f-279e736002cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "meses = meses.reset_index()\n",
    "del meses['index']\n",
    "display(meses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e516903-0baf-4a77-a60d-0a4510457a20",
   "metadata": {},
   "source": [
    "Realizada o procedimento de identificação dos tipos de dados existentes no código, inicia-se o processo de normalização de dados. Ela é ocorrente por meio do comando \"zscore\". Esse processo de normalização é extremamente importante para análises estátisticas, principalmente ao considerar que esse processo é remetente a transformação em escala da distribuição de uma variável para poder fazer comparações entre conjunto de elementos, evitando o efeito de influências."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b824a2d1-fa2d-4bdf-9460-3f5b2e491c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_maximo = meses['numero_dias_sem_chuva'].max()\n",
    "#c_minimo = meses['numero_dias_sem_chuva'].min()\n",
    "\n",
    "#p_maximo = meses['precipitacao'].max()\n",
    "#p_minimo = meses['precipitacao'].min()\n",
    "\n",
    "#lat_maximo = meses['lat'].max()\n",
    "#lat_minimo = meses['lat'].min()\n",
    "\n",
    "#lon_maximo = meses['lon'].max()\n",
    "#lon_minimo = meses['lon'].min()\n",
    "\n",
    "#meses['numero_dias_sem_chuva'] = (meses['numero_dias_sem_chuva'] - c_minimo) / (c_maximo - c_minimo)\n",
    "#meses['precipitacao'] = (meses['precipitacao'] - p_minimo) / (p_maximo - p_minimo)\n",
    "#meses['lat'] = (meses['lat'] - lat_minimo) / (lat_maximo - lat_minimo)\n",
    "#meses['lon'] = (meses['lon'] - lon_minimo) / (lon_maximo - lon_minimo)\n",
    "\n",
    "\n",
    "#display(meses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e64f07d-6c48-40f0-a9a2-e36265e9b059",
   "metadata": {},
   "source": [
    "### **Análise de Dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b14abd-d889-4df1-ac5d-a5c66841692b",
   "metadata": {},
   "source": [
    "De modo a analisar os dados obtidos, identifica-se informações estatísticas sobre cada amostra mensal de dados. Inicialmente, realiza-se o plot da descrição estátisca dos dados, como obter, por exemplo: a média e a moda. Em seguida, realiza-se o plot dos gráficos por meio de uma matriz de covariância e correlação entre os atríbutos para analisar as relações entre os atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f17cc6-7fda-4402-a3ed-28bdc89c2f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de gráficos scatter \n",
    "sns.pairplot(meses, height=3);\n",
    "\n",
    "# mostra o gráfico usando a função show() da matplotlib\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a530c42-0fc0-4ffa-a5d5-aced445cc4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de covâriancia\n",
    "mes_covariancia = meses.cov()\n",
    "\n",
    "# Matriz de correlação\n",
    "mes_correlacao = meses.corr()\n",
    "\n",
    "print('Matriz de covariância: ')\n",
    "display(mes_covariancia)\n",
    "\n",
    "print('\\n\\nMatriz de correlação: ')\n",
    "display(mes_correlacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1d60a8-87a7-46e5-a415-3dee23914026",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = [\"lat\", \"lon\", \"numero_dias_sem_chuva\", \"precipitacao\", \"risco_fogo\", \"data_hora_gmt\"]\n",
    "sns.heatmap(mes_correlacao, annot=True, fmt='g', xticklabels=labs, yticklabels=labs, cmap='seismic', center = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639049a0-ad9c-4d38-b9e2-c2dd8c2adb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = meses.plot(kind='scatter', x=\"precipitacao\", y=\"risco_fogo\", color='Red', label=\"Meses\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e75f5a-467c-438b-9a7e-02c0c514a4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "meses.plot(kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d44251-44c5-4ef8-b832-dcf76fbd10ab",
   "metadata": {},
   "source": [
    "# Bloco 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcacf548-cab3-4eb3-aebe-d8e3ab240221",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAMANHO_TESTE = 0.1 # fração de dados utilizada para teste: 10%\n",
    "SEMENTE_ALEATORIA = 61455 # semente escolhida aleatoriamente\n",
    "DATASET_NAME = \"meses\"\n",
    "FEATURES = [\"numero_dias_sem_chuva\", \"precipitacao\", \"lat\", \"lon\"]\n",
    "TARGET = [\"risco_fogo\"]\n",
    "\n",
    "indices = meses.index\n",
    "indices_treino, indices_teste = train_test_split(\n",
    "    indices, test_size=TAMANHO_TESTE, random_state=SEMENTE_ALEATORIA\n",
    ")\n",
    "\n",
    "meses_treino = meses.loc[indices_treino]\n",
    "meses_teste = meses.loc[indices_teste]\n",
    "\n",
    "X_treino = meses_treino.reindex(FEATURES, axis=1).values\n",
    "y_treino = meses_treino.reindex(TARGET, axis=1).values\n",
    "X_teste = meses_teste.reindex(FEATURES, axis=1).values\n",
    "y_teste = meses_teste.reindex(TARGET, axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d23d128-f3eb-4ed7-8212-74d5a8a9910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador_x = MinMaxScaler()\n",
    "normalizador_y = MinMaxScaler()\n",
    "\n",
    "normalizador_x.fit(X_treino)\n",
    "normalizador_y.fit(y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2047dce3-87a9-41a1-b459-822720361831",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ecf0a5-c428-4119-9a39-98f8f5b189c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria o modelo\n",
    "modelo_baseline = DummyRegressor()\n",
    "# treina o modelo\n",
    "modelo_baseline.fit(normalizador_x.transform(X_treino),normalizador_y.transform(y_treino))\n",
    "\n",
    "# realiza uma previsão usando o modelo treinado\n",
    "previsao = modelo_baseline.predict(normalizador_x.transform(X_treino))\n",
    "#previsao = normalizador_y.inverse_transform(previsao)\n",
    "print(previsao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e878035-6544-4ed1-b196-d50451af967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_verdadeiro = y_teste\n",
    "y_previsao = modelo_baseline.predict(normalizador_x.transform(X_teste))\n",
    "#y_previsao = normalizador_y.inverse_transform(y_previsao)\n",
    "\n",
    "RMSE = mean_squared_error(y_verdadeiro, y_previsao, squared=False)\n",
    "\n",
    "print(f\"O RMSE do modelo linear foi de {RMSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dc6d38-2374-40f0-90bd-23af503c7bd9",
   "metadata": {},
   "source": [
    "# K-vizinhos mais próximos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fd2da3-08a9-4e0f-b11d-5535d08622e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria o modelo\n",
    "modelo_knm = KNeighborsRegressor()\n",
    "\n",
    "# treina o modelo\n",
    "modelo_knm.fit(\n",
    "    normalizador_x.transform(X_treino),\n",
    "    normalizador_y.transform(y_treino),\n",
    ")\n",
    "\n",
    "# realiza uma previsão usando o modelo treinado\n",
    "previsao = modelo_knm.predict(normalizador_x.transform(X_treino))\n",
    "previsao = normalizador_y.inverse_transform(previsao)\n",
    "print(previsao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b64230e-ff19-44fd-b9fb-6d894a22a863",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_VIZINHOS = [1, 5, 10]\n",
    "\n",
    "for n in NUM_VIZINHOS:\n",
    "    modelo_knn = KNeighborsRegressor(n_neighbors=n)\n",
    "\n",
    "    modelo_knm.fit(normalizador_x.transform(X_treino),normalizador_y.transform(y_treino))\n",
    "    y_verdadeiro = y_teste\n",
    "    y_previsao = modelo_knm.predict(normalizador_x.transform(X_teste))\n",
    "    y_previsao = normalizador_y.inverse_transform(y_previsao)\n",
    "    RMSE = mean_squared_error(y_verdadeiro, y_previsao, squared=False)\n",
    "    print(f\"O RMSE do modelo linear foi de {RMSE} com {n} vizinhos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c113e86-54cb-464e-aed7-da102bb554e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test set\n",
    "neighbors = np.arange(1, 9)\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    " \n",
    "# Loop over K values\n",
    "for i, k in enumerate(neighbors):\n",
    "    modelo_knm = KNeighborsRegressor(n_neighbors=k)\n",
    "    modelo_knm.fit(normalizador_x.transform(X_treino),normalizador_y.transform(y_treino))\n",
    "\n",
    "    # Compute training and test data accuracy\n",
    "    train_accuracy[i] = modelo_knm.score(normalizador_x.transform(X_teste), normalizador_y.transform(y_teste))\n",
    "    test_accuracy[i] = modelo_knm.score(normalizador_x.transform(X_teste), normalizador_y.transform(y_teste))\n",
    " \n",
    "# Plot do Gráfico\n",
    "plt.plot(neighbors, test_accuracy, label = 'Teste de Precisão do Dataset')\n",
    "plt.plot(neighbors, train_accuracy, label = 'Treino de Precisão do Dataset')\n",
    " \n",
    "plt.legend()\n",
    "plt.xlabel('k_vizinhos')\n",
    "plt.ylabel('Precisão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9339d9f-4cca-4bf3-8a66-4bd4964a07a9",
   "metadata": {},
   "source": [
    "# Modelo de Regressão Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2864ce06-e59d-4fc9-8861-0a4fd1f00af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria o modelo\n",
    "modelo_linear = LinearRegression()\n",
    "\n",
    "# treina o modelo\n",
    "modelo_linear.fit(normalizador_x.transform(X_treino), normalizador_y.transform(y_treino))\n",
    "\n",
    "# realiza uma previsão usando o modelo treinado\n",
    "previsao = modelo_linear.predict(normalizador_x.transform(X_treino))\n",
    "previsao = normalizador_y.inverse_transform(previsao)\n",
    "print(previsao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac68a54c-81b4-4679-8a73-c3ba0bcca66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_verdadeiro = y_teste\n",
    "y_previsao = modelo_linear.predict(normalizador_x.transform(X_teste))\n",
    "y_previsao = normalizador_y.inverse_transform(y_previsao)\n",
    "\n",
    "RMSE = mean_squared_error(y_verdadeiro, y_previsao, squared=False)\n",
    "\n",
    "print(f\"O RMSE do modelo linear foi de {RMSE}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10479074-36e0-4e5c-ad72-34574a8e89de",
   "metadata": {},
   "source": [
    "## Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3727bc2-fcce-483f-98df-0cf1e5ba597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria o modelo\n",
    "modelo_dt = DecisionTreeRegressor(random_state=SEMENTE_ALEATORIA)\n",
    "\n",
    "# treina o modelo\n",
    "modelo_dt.fit(normalizador_x.transform(X_treino), normalizador_y.transform(y_treino))\n",
    "\n",
    "# realiza uma previsão usando o modelo treinado\n",
    "previsao = modelo_dt.predict(normalizador_x.transform(X_treino))\n",
    "previsao = normalizador_y.inverse_transform(previsao)\n",
    "print(previsao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c65196e-be97-4396-a148-c72d79bcb62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_verdadeiro = y_teste\n",
    "y_previsao = modelo_dt.predict(normalizador_x.transform(X_teste))\n",
    "y_previsao = normalizador_y.inverse_transform(y_previsao)\n",
    "\n",
    "RMSE = mean_squared_error(y_verdadeiro, y_previsao, squared=False)\n",
    "\n",
    "print(f\"O RMSE do modelo linear foi de {RMSE}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398068f8-c7ed-4a27-bb1a-19daf1f2d36a",
   "metadata": {},
   "source": [
    "## Classificação\n",
    "### com Floresta Aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ffea835e-2569-4d29-b1b3-4c10a4e56e86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'random_seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SOFIA2~1\\AppData\\Local\\Temp/ipykernel_33004/1816671685.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodelo_rf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSEMENTE_ALEATORIA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_treino\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_treino\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_teste\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_teste\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\venv\\ilumpy\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'random_seed'"
     ]
    }
   ],
   "source": [
    "modelo_rf = RandomForestClassifier(random_seed=SEMENTE_ALEATORIA)\n",
    "\n",
    "y_treino = y_treino.reshape()\n",
    "y_teste = y_teste.reshape()\n",
    "\n",
    "# treina o modelo\n",
    "modelo_rf.fit(X_treino, y_treino)\n",
    "\n",
    "# realiza uma previsão usando o modelo treinado\n",
    "previsao = modelo_rf.predict(X_teste)\n",
    "print(previsao)\n",
    "\n",
    "# Criação do Modelo\n",
    "\n",
    "\n",
    "previsao = modelo_rf.predict(X_teste_norm)\n",
    "\n",
    "print(previsao)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5a4643-3518-448c-b1dc-08b02fdc7d52",
   "metadata": {},
   "source": [
    "#### Métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567ee2a8-9ce7-4f46-9ee2-1b346cd1fef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b2dc55dd-3df4-4b70-9bc7-b731d6cdca5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SOFIA2~1\\AppData\\Local\\Temp/ipykernel_33004/2547165237.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"A precisão do modelo é de {round(accuracy_score(y_teste,previsao),3)*100} %\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\venv\\ilumpy\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\venv\\ilumpy\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\venv\\ilumpy\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: continuous is not supported"
     ]
    }
   ],
   "source": [
    "print(f\"A precisão do modelo é de {round(accuracy_score(y_teste,previsao),3)*100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "97c7ce23-bfae-42d2-ae14-990bea137d21",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "iterable argument unpacking follows keyword argument unpacking (Temp/ipykernel_33004/299440833.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\SOFIA2~1\\AppData\\Local\\Temp/ipykernel_33004/299440833.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    sklearn.metrics.precision_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')\u001b[0m\n\u001b[1;37m                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m iterable argument unpacking follows keyword argument unpacking\n"
     ]
    }
   ],
   "source": [
    "# sklearn.metrics.precision_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')\n",
    "\n",
    "precision_score(y_true, y_pred, average='macro')\n",
    "precision_score(y_true, y_pred, average='micro')\n",
    "precision_score(y_true, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "149d1ee7-44a7-46ec-b3d2-e28651826afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize = False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Greens): # muda a cor\n",
    "    plt.figure(figsize = (10, 10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, size = 24),\n",
    "    plt.colorbar(aspect=4),\n",
    "    tick_marks = np.arange(len(classes)),\n",
    "    plt.xticks(tick_marks, classes, rotation=45, size = 14)\n",
    "    plt.yticks(tick_marks, classes, size = 14),\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.    # Label the plot\n",
    "    for i, j in itertools.product(range(cm.shape[0]),\n",
    "        range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), \n",
    "        fontsize = 20,\n",
    "        horizontalalignment=\"center\",\n",
    "        color=\"white\" if cm[i, j] > thresh else \"black\"),\n",
    "    plt.grid(None)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', size = 18)\n",
    "    plt.xlabel('Predicted label', size = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4c6214-4a2d-4956-8dac-ba6db7b7d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar como confusion_matrix(y_test, y_pred)\n",
    "plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db580f24-54ca-4a71-9432-f6248146c8fb",
   "metadata": {},
   "source": [
    "#### HIPERPARÂMETROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62f01d6-552b-4a7f-aaaf-fe0e2cc03cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLHAS = [None, 6, 36]\n",
    "NUM_PROFUNDIDADE = [None, 3, 10]\n",
    "\n",
    "for n_folhas, n_profundidade in product(NUM_FOLHAS, NUM_PROFUNDIDADE):\n",
    "    modelo_dt = DecisionTreeRegressor(\n",
    "        max_leaf_nodes=n_folhas,\n",
    "        max_depth=n_profundidade,\n",
    "        random_state=SEMENTE_ALEATORIA,\n",
    "    )\n",
    "\n",
    "    modelo_dt.fit(normalizador_x.transform(X_treino), normalizador_y.transform(y_treino))\n",
    "\n",
    "    y_verdadeiro = y_teste\n",
    "    y_previsao = modelo_dt.predict(normalizador_x.transform(X_teste))\n",
    "    y_previsao = normalizador_y.inverse_transform(y_previsao)\n",
    "    RMSE = mean_squared_error(y_verdadeiro, y_previsao, squared=False)\n",
    "\n",
    "    print(\n",
    "        f\"O RMSE do modelo AD usando max_leaf_nodes={n_folhas} \"\n",
    "        f\"e max_depth={n_profundidade} foi de {RMSE:.2f}.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf8998f-6c6d-41da-8d41-8c7d8e8068c4",
   "metadata": {},
   "source": [
    "#### GRAFO DO MODELO DE ÁRVORE DE DECISÕES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e1e871-28c0-48ba-851d-44abc20311d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria e treina o modelo\n",
    "modelo_dt = DecisionTreeRegressor(\n",
    "    max_leaf_nodes=6,\n",
    "    random_state=SEMENTE_ALEATORIA,\n",
    ")\n",
    "modelo_dt.fit(normalizador_x.transform(X_treino), normalizador_y.transform(y_treino))\n",
    "\n",
    "# cria os objetos de figura e eixo\n",
    "fig, axe = plt.subplots(\n",
    "    ncols=1,\n",
    "    nrows=1,\n",
    "    figsize=(7, 4),\n",
    "    dpi=150,\n",
    ")\n",
    "\n",
    "# plota o grafo da árvore de decisão\n",
    "tree.plot_tree(\n",
    "    modelo_dt,\n",
    "    feature_names=FEATURES,\n",
    "    ax=axe,\n",
    "    impurity=False,\n",
    "    filled=True,\n",
    "    proportion=True,\n",
    "    precision=2,\n",
    ")\n",
    "\n",
    "# mostra o plot para o usuário\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
